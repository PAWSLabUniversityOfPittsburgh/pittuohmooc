---
title: "Visualizing The Fullest Model."
subtitle: "Previous Submission. 4 Behaviors."
author: "Michael V. Yudelson"
date: "12/30/2016"
output: pdf_document
header-includes:
  - \usepackage{color}
---

```{r, echo=FALSE, warning=FALSE}
# Context, global settings for this particular TFM
library(ggplot2)
library(knitr)
tfm_tag="PS4"
tfm_tag_long="Previous Submission 4 Behaviors"
tfm_fig_path=paste("./result/TFM_",tfm_tag,"/",sep="")
load("../code/visualizeTheFullestModel.RData")
parameter_table = data.frame()
```

This file is the visualization of **The Fullest Model** that merges PFA logistic regression model with a set of behavior-capturing parameters. The following sections focus on individual parameters, parameter groups, and parameter pools. This particular visuzlization is for <span style="color:blue">{`r tfm_tag_long`}</span>.


# Student Intercepts

Student intercepts account for overall student ability influencing their tendency to exhibit better/worse performance.

```{r, echo=FALSE, fig.height=3, fig.width=4,fig.align='center',warning=FALSE}
value = int_student
main = "global student intercept Distribution"
plot(density(value),main=main,sub=paste("Mean,SD,Median=",round(mean(value),digits=3),",",round(sd(value),digits=3),",",round(median(value),digits=3),sep=""),cex=0.2)
abline(v=mean(value),col="red",lty=1)
abline(v=median(value),col="red",lty=2)
abline(v=mean(value)+sd(value),col="red",lty=3)
abline(v=mean(value)-sd(value),col="red",lty=3)
legend("topright",legend=c("mean","median","+/- sd"),col="red",lty=1:3)
parameter_table = rbind(parameter_table, data.frame(variable=main,mean=mean(value),sd=sd(value)))
```

**Notes**: Distribution of student abilities is roughly symmetrical with a small SD=`r round(sd(value),digits=3)`.

#  Behavior intercept

Behavior intercept accounts for the whether certain behavior was exhibited or not since last code submission to current submission. The `r nB`'th behavior (*`r b[nB]`*) is excluded as a reference category.

```{r, echo=FALSE, fig.height=3, fig.width=4,fig.align='center',warning=FALSE}
value = int_behav
main = "exhibiting behavior or not since last submission"
barplot(value,main=main,names.arg=b[1:(nB-1)])
```

**Notes**: Exhibiting *building* behavior since previois submission before current submission has a large positive effect. Exhibiting *reducing* behavior has less effect. *Massaging* has zero effect.


# Student intercept within behavior

Per-student correction for the behavior intercept since last code submission to current submission. 

```{r, echo=FALSE, fig.height=3, fig.width=4,fig.align='center',warning=FALSE}
value = int_student_wi_behav
main = "student intercept w/in behaviors"
labels = NULL
df = data.frame()
for(i in 1:(nB-1)){
  labels = c(labels,paste(b[i],", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  parameter_table = rbind(parameter_table, data.frame(variable=paste(main," (",b[i],")",sep=""),mean=mean(value[,i]),sd=sd(value[,i])))
}
for(i in 1:(nB-1)){
  df = rbind(df, data.frame(intercept=value[,i], behavior=rep(labels[i],dim(value)[1])))
}
anova_pval = summary(aov(intercept~behavior,data=df))[[1]][,"Pr(>F)"][1]
ggplot(data=df,aes(x=intercept,colour=behavior)) + geom_density() + labs(title = paste(main," (ANOVA p=",round(anova_pval,digits=3),")",sep=""))
```

**Notes**: Per-student corrections for the intercept of exhibiting the *massaging* behavior since last submission are all zero (just like the fixed intercept as well). Per-student corrections for *building* and *reducing* behaviors are approximately symmetrically distributed. *Building* per-student corrections are slightly wider spread (`r round(sd(value[,1]),digits=3)` vs. `r round(sd(value[,2]),digits=3)`)

```{r, echo=FALSE, fig.height=3, fig.width=8,fig.align='center', warning=FALSE}
par(mfrow=c(1,nB-1))
for(i in 1:(nB-2)){
  for(j in (i+1):(nB-1)){
    ct = cor.test(value[,j],value[,i])
    plot(value[,i],value[,j], main=paste("Contrasts for",main),xlab=labels[i],ylab=labels[j],sub=paste("R=",round(ct$estimate,digits=3)," (pval=",sprintf("%5.3f",ct$p.value),")",sep=""))
    abline(lm(value[,j]~value[,i]),col="red")
  }
}
```

#  Problem intercept within behavior

Per-problem correction for the behavior intercept since last code submission to current submission.

```{r, echo=FALSE, fig.height=4, fig.width=6,fig.align='center',warning=FALSE}
value = int_problem_wi_behav
main = "prob. intercept w/in behaviors"
labels = NULL
df = data.frame()
for(i in 1:(nB-1)){
  labels = c(labels,paste(b[i],", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
}
for(i in 1:(nB-1)){
  df = rbind(df, data.frame(intercept=value[,i], behavior=rep(labels[i],dim(value)[1])))
}
anova_pval = summary(aov(intercept~behavior,data=df))[[1]][,"Pr(>F)"][1]
ggplot(data=df,aes(x=intercept,colour=behavior)) + geom_density() + labs(title = paste(main," (ANOVA p=",round(anova_pval,digits=3),")",sep=""))
```


```{r, echo=FALSE, fig.height=12, fig.width=4,fig.align='center', warning=FALSE}
par(mfrow=c(nB-1,1))
for(i in 1:(nB-2)){
  for(j in (i+1):(nB-1)){
    ct = cor.test(value[,j],value[,i])
    plot(value[,i],value[,j], main=paste("Contrasts for",main),xlab=labels[i],ylab=labels[j],sub=paste("R=",round(ct$estimate,digits=3)," (pval=",sprintf("%5.3f",ct$p.value),")",sep=""))
    abline(lm(value[,j]~value[,i]),col="red")
  }
}
```

#  Slope for behaviors since previous submit

Behavior slope accounts for amount certain behavior was exhibited since last code submission to current submission. The count of occurences is transformed using `log(x+1)` function.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = slope_behav_since_prev_submit
main = "slope behavior since previous submit"
barplot(value,main=main,names.arg=b)
```

#  Slope for behaviors since beginning of the student work

Behavior slope accounts for amount certain behavior was exhibited since the start of the student work. The count of occurences is transformed using `log(x+1)` function.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = slope_behav_for_user
main = "slope behavior for user"
barplot(value,main=main,names.arg=b)
```

#  Slope for behaviors since beginning of the problem

Behavior slope accounts for amount certain behavior was exhibited since the start of the problem. The count of occurences is transformed using `log(x+1)` function.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = slope_behav_for_problem
main = "slope behavior for problem"
barplot(value,main=main,names.arg=b)
```

#  Per-student correction for slope of behaviors since previous submit

Per-student correction for behavior slope that accounts for amount certain behavior was exhibited since last code submission to current submission. The count of occurences is transformed using `log(x+1)` function.

```{r, echo=FALSE, fig.height=4, fig.width=6,fig.align='center',warning=FALSE}
value = slope_user_wi_behav_since_prev_submit
main = "user slope w/in behavior since prev submit"
labels = NULL
df = data.frame()
for(i in 1:(nB-1)){
  labels = c(labels,paste(b[i],", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  parameter_table = rbind(parameter_table, data.frame(variable=paste(main," (",b[i],")",sep=""), mean=mean(value[,i]),sd=sd(value[,i])))
}
for(i in 1:(nB-1)){
  df = rbind(df, data.frame(intercept=value[,i], behavior=rep(labels[i],dim(value)[1])))
}
anova_pval = summary(aov(intercept~behavior,data=df))[[1]][,"Pr(>F)"][1]
ggplot(data=df,aes(x=intercept,colour=behavior)) + geom_density() + labs(title = paste(main," (ANOVA p=",round(anova_pval,digits=3),")",sep=""))
```

```{r, echo=FALSE, fig.height=12, fig.width=4,fig.align='center',warning=FALSE}
par(mfrow=c(nB-1,1))
for(i in 1:(nB-2)){
  for(j in (i+1):(nB-1)){
    ct = cor.test(value[,j],value[,i])
    plot(value[,i],value[,j], main=paste("Contrasts for",main),xlab=labels[i],ylab=labels[j],sub=paste("R=",round(ct$estimate,digits=3)," (pval=",sprintf("%5.3f",ct$p.value),")",sep=""))
    abline(lm(value[,j]~value[,i]),col="red")
  }
}
```


#  Per-student correction for Slope on behaviors since beginning of the student work

Per-student correction for behavior slope that accounts for amount certain behavior was exhibited since the start of the student work. The count of occurences is transformed using `log(x+1)` function.

```{r, echo=FALSE, fig.height=4, fig.width=6,fig.align='center',warning=FALSE}
value = slope_user_wi_behav_since_start
main = "user slope w/in behavior since start of work"
labels = NULL
df = data.frame()
for(i in 1:(nB-1)){
  labels = c(labels,paste(b[i],", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  parameter_table = rbind(parameter_table, data.frame(variable=paste(main," (",b[i],")",sep=""),mean=mean(value[,i]),sd=sd(value[,i])))
}
for(i in 1:(nB-1)){
  df = rbind(df, data.frame(intercept=value[,i], behavior=rep(labels[i],dim(value)[1])))
}
anova_pval = summary(aov(intercept~behavior,data=df))[[1]][,"Pr(>F)"][1]
ggplot(data=df,aes(x=intercept,colour=behavior)) + geom_density() + labs(title = paste(main," (ANOVA p=",round(anova_pval,digits=3),")",sep=""))
```

```{r, echo=FALSE, fig.height=12, fig.width=4,fig.align='center',warning=FALSE}
par(mfrow=c(nB-1,1))
for(i in 1:(nB-2)){
  for(j in (i+1):(nB-1)){
    ct = cor.test(value[,j],value[,i])
    plot(value[,i],value[,j], main=paste("Contrasts for",main),xlab=labels[i],ylab=labels[j],sub=paste("R=",round(ct$estimate,digits=3)," (pval=",sprintf("%5.3f",ct$p.value),")",sep=""))
    abline(lm(value[,j]~value[,i]),col="red")
  }
}
```

#  Per-student correction for Slope on behaviors since beginning of the problem

Per-student correction for behavior slope that accounts for amount certain behavior was exhibited since the start of the problem. The count of occurences is transformed using `log(x+1)` function.

```{r, echo=FALSE, fig.height=4, fig.width=6,fig.align='center',warning=FALSE}
value = slope_user_wi_behav_since_problem_start
main = "user slope w/in behavior since prob. start"
labels = NULL
df = data.frame()
for(i in 1:(nB-1)){
  labels = c(labels,paste(b[i],", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  parameter_table = rbind(parameter_table, data.frame(variable=paste(main," (",b[i],")",sep=""), mean=mean(value[,i]),sd=sd(value[,i])))
}
for(i in 1:(nB-1)){
  df = rbind(df, data.frame(intercept=value[,i], behavior=rep(labels[i],dim(value)[1])))
}
anova_pval = summary(aov(intercept~behavior,data=df))[[1]][,"Pr(>F)"][1]
ggplot(data=df,aes(x=intercept,colour=behavior)) + geom_density() + labs(title = paste(main," (ANOVA p=",round(anova_pval,digits=3),")",sep=""))
```

```{r, echo=FALSE, fig.height=12, fig.width=4,fig.align='center',warning=FALSE}
par(mfrow=c(nB-1,1))
for(i in 1:(nB-2)){
  for(j in (i+1):(nB-1)){
    ct = cor.test(value[,j],value[,i])
    plot(value[,i],value[,j], main=paste("Contrasts for",main),xlab=labels[i],ylab=labels[j],sub=paste("R=",round(ct$estimate,digits=3)," (pval=",sprintf("%5.3f",ct$p.value),")",sep=""))
    abline(lm(value[,j]~value[,i]),col="red")
  }
}
```

# Skill intercept

Skill intercept is the overall **easyness** of the skill. The higher the value, the easier the skill.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = int_skill
main = "skill intercept"
plot(density(value),main=main,sub=paste("Mean,SD,Median=",round(mean(value),digits=3),",",round(sd(value),digits=3),",",round(median(value),digits=3),sep=""))
abline(v=mean(value),col="red",lty=1)
abline(v=median(value),col="red",lty=2)
abline(v=mean(value)+sd(value),col="red",lty=3)
abline(v=mean(value)-sd(value),col="red",lty=3)
legend("topleft",legend=c("mean","median","+/- sd"),col="red",lty=1:3)
```

# Skill intercept within the problem

Skill within problem intercept is the overall **easyness** of the skill for a particular problem. The higher the value, the easier the skill.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = int_skill_wi_problem
main = "skill intercept w/in problem"
plot(density(value),main=main,sub=paste("Mean,SD,Median=",round(mean(value),digits=3),",",round(sd(value),digits=3),",",round(median(value),digits=3),sep=""))
abline(v=mean(value),col="red",lty=1)
abline(v=median(value),col="red",lty=2)
abline(v=mean(value)+sd(value),col="red",lty=3)
abline(v=mean(value)-sd(value),col="red",lty=3)
legend("topleft",legend=c("mean","median","+/- sd"),col="red",lty=1:3)
```

```{r, echo=FALSE, fig.height=4, fig.width=7,fig.align='center',warning=FALSE}
value = int_skill_wi_problem
main = "skill intercept w/in problem"
labels = NULL
df = data.frame()
sds = NULL
means = NULL
for(i in 1:(nP)){
  labels = c(labels,paste("prob. ",i,", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  means = c(means,mean(value[,i]))
  sds = c(sds,sd(value[,i]))
}
par(mfrow=c(1,2))
plot(density(means),main=main,sub="problem means")
plot(density(sds),main=main,sub="problem SDs")
```

```{r, echo=FALSE, fig.height=4, fig.width=7,fig.align='center',warning=FALSE}
ix = sort(means, index.return=TRUE)$ix
plot(1:nP, means[ix], ylim=range(c(means[ix]-sds[ix], means[ix]+sds[ix])), pch=19, xlab="Problem", ylab="w/in prob. M(SD)", main=main)
arrows(1:nP, means[ix]-sds[ix], 1:nP, means[ix]+sds[ix], length=0.05, angle=90, code=3)
```


# Skill slope (all oportunities)

Skill slope is the rate of learning the skill from every opportunity (submission of the code).

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = slope_skill
main = "skill slope"
plot(density(value),main=main,sub=paste("Mean,SD,Median=",round(mean(value),digits=3),",",round(sd(value),digits=3),",",round(median(value),digits=3),sep=""))
abline(v=mean(value),col="red",lty=1)
abline(v=median(value),col="red",lty=2)
abline(v=mean(value)+sd(value),col="red",lty=3)
abline(v=mean(value)-sd(value),col="red",lty=3)
legend("topright",legend=c("mean","median","+/- sd"),col="red",lty=1:3)
```


# Skill slope (failed oportunities)

Skill slope for the failed opportunities is the rate of learning the skill when code submission is not fully correct.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
value = slope_skill_fail
main = "skill slope for failures"
plot(density(value),main=main,sub=paste("Mean,SD,Median=",round(mean(value),digits=3),",",round(sd(value),digits=3),",",round(median(value),digits=3),sep=""))
abline(v=mean(value),col="red",lty=1)
abline(v=median(value),col="red",lty=2)
abline(v=mean(value)+sd(value),col="red",lty=3)
abline(v=mean(value)-sd(value),col="red",lty=3)
legend("topright",legend=c("mean","median","+/- sd"),col="red",lty=1:3)
```

# Comparing skill slopes for all opportunities vs. faled opportunities

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
ct = cor.test(slope_skill_fail,slope_skill)
plot(slope_skill,slope_skill_fail, sub=paste("R=",round(ct$estimate,digits=3)," (pval=",sprintf("%5.3f",ct$p.value),")",sep=""),xlab="skill slope",ylab="skill slope for failures")
abline(lm(slope_skill_fail~slope_skill),col="red")
```

# Skill slope within a problem (all oportunities)

Skill slope is the rate of learning the skill from every opportunity (submission of the code) in a particular problem.

```{r, echo=FALSE, fig.height=4, fig.width=7,fig.align='center',warning=FALSE}
value = slope_skill_wi_problem
main = "skill slope w/in problem"
labels = NULL
df = data.frame()
sds = NULL
means = NULL
for(i in 1:(nP)){
  labels = c(labels,paste("prob. ",i,", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  means = c(means,mean(value[,i]))
  sds = c(sds,sd(value[,i]))
}
par(mfrow=c(1,2))
plot(density(means),main=main,sub="distribution of prob. means")
plot(density(sds),main=main,sub="distribution of prob. SDs")
```

```{r, echo=FALSE, fig.height=4, fig.width=7,fig.align='center',warning=FALSE}
ix = sort(means, index.return=TRUE)$ix
plot(1:nP, means[ix], ylim=range(c(means[ix]-sds[ix], means[ix]+sds[ix])), pch=19, xlab="Problem", ylab="w/in prob. M(SD)", main=main)
arrows(1:nP, means[ix]-sds[ix], 1:nP, means[ix]+sds[ix], length=0.05, angle=90, code=3)
```

# Skill slope within a problem (failed oportunities)

Skill slope for the failed opportunities is the rate of learning the skill within a particular problem when code submission is not fully correct.

```{r, echo=FALSE, fig.height=4, fig.width=7,fig.align='center',warning=FALSE}
value = slope_skill_fail_wi_problem
main = "skill fail slope w/in problem"
labels = NULL
df = data.frame()
sds = NULL
means = NULL
for(i in 1:(nP)){
  labels = c(labels,paste("prob. ",i,", M(SD)=",round(mean(value[,i]),digits=3),"(",round(sd(value[,i]),digits=3),")",sep=""))
  means = c(means,mean(value[,i]))
  sds = c(sds,sd(value[,i]))
}
par(mfrow=c(1,2))
plot(density(means),main=main,sub="distribution of prob. means")
plot(density(sds),main=main,sub="distribution of prob. SDs")
```

```{r, echo=FALSE, fig.height=4, fig.width=7,fig.align='center',warning=FALSE}
ix = sort(means, index.return=TRUE)$ix
plot(1:nP, means[ix], ylim=range(c(means[ix]-sds[ix], means[ix]+sds[ix])), pch=19, xlab="Problem", ylab="w/in prob. M(SD)", main=main)
arrows(1:nP, means[ix]-sds[ix], 1:nP, means[ix]+sds[ix], length=0.05, angle=90, code=3)
```

# Intercept

Overall regression intercept.

```{r, echo=FALSE, fig.height=4, fig.width=4,fig.align='center',warning=FALSE}
barplot(bias)
```

# Comparing Standard Deviations of the Pooled Variables

```{r, echo=FALSE}
kable(parameter_table, format = "latex")
```